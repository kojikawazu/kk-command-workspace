# Terraform を用いた AWS IaC のベストプラクティスと代表的なアーキテクチャ

## AWSにおける IaC（Infrastructure as Code）のベストプラクティス

Terraformを利用したAWSインフラ構築では、インフラ定義をコードで管理することで一貫性や再現性を高め、変更履歴の追跡やレビューを容易にします​。以下、特にAWS×Terraformを想定したベストプラクティスを解説します。

- コードのモジュール化と構成管理:
  - Terraformコードは環境（開発・ステージング・本番など）やコンポーネント（ネットワーク、アプリケーション層、データベース等）ごとに再利用可能なモジュールに分割します。モジュール化によりインフラ構成を論理的な単位で表現でき、チーム間での再利用や保守が容易になります​。ただし過度なネストは避け、モジュールの入れ子は1〜2階層程度に留めます​。単一リソースを包むだけの薄いモジュールは不要で、明確な抽象化単位がある場合にモジュール化します​。モジュールは内部でプロバイダ設定を行わず、外部から必要なプロバイダを受け取る形にし（プロバイダのバージョン要件のみrequired_providersで宣言）、どのAWSリージョンやアカウントに適用するかといった具体設定はルートモジュール側で定義します​。これによりモジュールの汎用性と移植性が向上します​。

- リポジトリ構成と命名規則:
  - Terraformコードのリポジトリは標準的な構成に従います。例えば「ルートモジュール用ディレクトリ」と「modulesディレクトリ（再利用モジュール群）」を用意し、各モジュールには main.tf（主要リソース定義）、variables.tf（入力変数定義）、outputs.tf（出力値定義）、README.md（用途と入出力の説明）を含めます​。変数や出力には用途を示す説明文を付記し、必要に応じデフォルト値を設定します​。リソースや変数の命名規則は一貫性と可読性を重視します。Terraformのベストプラクティスではリソース名はスネークケース（example_resourceのように小文字＋アンダースコア）を推奨し​、一意で分かりやすい名前（例：「primary」「replica」「web_server」等）を付けます​。環境名や用途を名前に含めるプレフィックス/サフィックスのルールを決めておくと、複数環境・複数アカウント間でリソースを識別しやすくなります​。また、AWSタグを活用した命名も有効です（後述）。変数名には単位（例：storage_size_gb）やブーリアンは肯定形（例：enable_feature_x）を含めるなどのルールも有用です​。

- コードスタイルと検証:
  - コードはterraform fmt等でフォーマットし、自動整形やlint（例：TFLint）をCIで実行してスタイルや簡易エラーをチェックします​。またterraform validateで構文検証、terraform planで変更内容を確認してから適用するワークフローを徹底します。Terraform実行時は原則まずプラン(plan)を実行し、内容をレビューしてからapplyするのが安全策です（GitOps的運用ではplan結果をPRに貼り付けてレビューするといった手法があります）​。複数人でIaCを開発する場合、Pull Requestベースでコードレビューを行い、CIで自動テストやプラン実行、静的解析を組み込むことで品質を維持します。

- 公式モジュールや再利用可能コンポーネントの活用:
  - AWS対応のTerraformレジストリ上には多数のコミュニティモジュール（例：VPCやALB、ECS、EKS構築用の汎用モジュール）が公開されています。信頼できるモジュール（公式または実績あるもの）を活用することで、自前で複雑なリソース周りのコードを書く手間を省け、バグの減少やベストプラクティスの追従につながります​。独自モジュールを作成する場合も、将来的にTerraform Registryで公開できる水準（READMEやバージョニングの整備）を目指すとよいでしょう。

- デフォルトタグとリソース管理:
  - AWSリソースには可能な限りタグを付与し、環境名・サービス名・所有者・コストセンターなどを明示します。Terraform AWSプロバイダではすべてのリソースに共通タグを付ける仕組み（default_tags設定）があるため、ルートモジュールで設定すると自動的に全リソースに付与できます。例えばEnvironment=prodやProject=MyService等のタグを一括管理することで、コスト分析や資産管理が容易になります（AWSのコストエクスプローラでタグ別集計するケースなど）。タグによりガバナンスを効かせ、不要リソースの洗い出しや運用自動化（タグでスケジュール停止するLambda関数連携等）にも役立ちます。

- 状態管理(バックエンド)と構成の分離:
  - Terraformの状態ファイル(tfstate)はインフラの現況を示す重要ファイルです。リモートバックエンドを利用して状態を共有・保護するのが必須となります。特にS3をバックエンドとし、DynamoDBでロックを有効にする構成はAWS上の標準パターンです​。S3は高耐久・高可用なストレージであり、バージョニングとサーバサイド暗号化(SSE)を有効化することで状態履歴の保全と不正閲覧防止が可能です​。またDynamoDBによる状態ロックにより複数人が同時にapplyして状態が競合するのを防ぎます​。状態ファイルにはリソースの機密情報（例：RDSパスワードのハッシュ値等）が含まれる場合もあるため、アクセス制御も重要です。状態格納用のS3バケットはTerraform実行に必要な最小限のIAM権限のみ許可し、他から直接アクセスできないようポリシーでロックダウンします​。またCloudTrailをS3に連携してPutObject/DeleteObject操作を監査すれば、誰がいつ状態を変更したか追跡可能です​。環境ごとに別バックエンドを使うことも強く推奨されます。開発・検証と本番で状態を分離すれば、誤って本番環境を変更するリスクを低減できます​。Terraformには一つの構成でワークスペースを切り替えることで状態を分離する機能もありますが、ワークスペースだけで環境を分ける運用は推奨度が低いです​。なぜなら人的ミスで誤ったワークスペースに適用してしまう可能性があり、環境間の完全分離という点ではバックエンド自体を別にする方が安全だからです​。従って、AWSアカウントやリージョンごとにS3バケットやワークスペースを分離し、Terraformのコード上も環境ごとに変数やtfvarsファイルで明示的に切り替える構成が望ましいでしょう。

以上のベストプラクティスを導入することで、TerraformによるAWSインフラ管理の可搬性・可読性・共同作業性が向上し、結果的にリスクやコストの削減にもつながります​。

## セキュリティ対策（IAM権限・状態・シークレット管理など）

TerraformによるIaC運用では、クラウド資源への強力な操作権限を扱うため、セキュリティ管理が非常に重要です。以下の観点で代表的な対策を示します​。

- 最小権限のIAMポリシー:
  - Terraform実行に用いるIAMユーザ/ロールには、必要最小限の権限だけを付与します（原則最小権限）​。例えばTerraformからEC2とS3を操作するなら、それらに限定したIAMポリシーとするべきです。過剰な権限を与えると、誤設定で想定外のリソースを変更・削除したり、認証情報漏えい時に被害が拡大するリスクがあります​。IAM Access Analyzer等を活用して未使用権限を検出し除去する、ポリシーにタグや条件を使って誤適用を防ぐ、といった工夫も有用です​。Terraform管理下のリソース自体にもタグベースの制限等で本番の重要資源を保護するなど、多層的に最小権限原則を適用します。

- IAMロールの活用（長期アクセスキー廃止）:
  - TerraformがAWSとやりとりする認証には可能な限りIAMロールを使います。IAMユーザーのアクセスキーを直接使う運用は避け、AWS上でTerraformを実行する場合は適切なロールをAssume Roleする形にします。IAMロールは一時的なセッション認証を発行するため長期キー管理が不要になり、安全性が向上します​。例えばCI/CDサーバや開発者のPCからTerraformを実行する際も、一旦自分のIAMユーザからTerraform用IAMロールをAssumeさせて一時クレデンシャルを取得し、そのクレデンシャルで実行する方法が推奨されます​。このようにすれば平常時に長期キーを保持せずに済み、キー漏えいリスクを低減できます。どうしても古いツールでロールが使えない場合は、Terraform専用のIAMユーザを発行し、そのアクセスキーに厳格なポリシー（IP制限や多要素認証デバイスからのAssumeしか許可しない等）を適用します。

- 機密情報の管理（Secret管理）:
  - Terraform定義中にパスワードや認証キーなどのシークレットを直接ハードコーディングしないようにします。Terraformの状態ファイルには出力変数などを通じて平文で機密値が含まれる場合があります。そのため、DBパスワードやAPIキー等はterraform.tfvarsや変数で渡すとしても極力Terraformでは平文を扱わず、AWS Secrets ManagerやSSMパラメータストアを併用します​。たとえばTerraformからSecrets Managerにシークレットを登録し、EC2やLambdaにはその参照ARNだけ渡す、といった構成にすると、Terraformの状態やコード中に平文シークレットが残りません。Terraformの機能としても、sensitiveフラグを変数や出力に付けておけばplanやapply出力時に値がマスクされます​。これらを活用し、シークレットは外部保管・参照する方針を徹底します。

- Terraform状態の保護:
  - 前述のとおり、リモートバックエンドの状態ファイルには機微情報が含まれる可能性があります。S3に保存する場合はバケット暗号化(SSE)を有効化し静止データを保護します​。またS3バケットやDynamoDBテーブルへのアクセス権はTerraform実行に必要なロールのみに限定し、不必要に閲覧・変更できないようにします​。状態ファイルが改ざん・破損すると大きな障害となるため、S3バケットでバージョニングや削除防止設定を有効にし、誤削除時も復元できるように備えます​。状態の変更操作は基本的にCI/CDから行い、人間が直接バックエンドを書き換えることは緊急時以外禁止します​。万一手動でロック解除や状態編集が発生したら検知できるよう、DynamoDBのロック解除ログやS3の変更通知を監視し、イレギュラーな操作にアラートを上げる運用も考えられます​。

- インフラとコードの継続的なセキュリティチェック:
  - Terraform定義およびデプロイ後のリソースに対し、セキュリティスキャンを継続的に行います。コード面では静的解析ツール（Checkovやtfsecなど）をCIに組み込み、既知のセキュリティ違反やMisconfiguration（公開設定のS3バケットや暗号化漏れなど）をプルリクエスト段階で検出します​。デプロイ後のAWS環境にはInspectorやAWS Config、Security Hub等のクラウドネイティブなセキュリティサービスを有効化し、ポリシールール違反や脆弱性を検知します​。例えばセキュリティグループが意図せず0.0.0.0/0を許可してしまった場合にSecurity Hubで検知し通知、Terraformコードを修正するといったサイクルです​。定期的なスキャン結果を踏まえ、Terraformコード側でタグ付けの強制やポリシー改善を行い、セキュリティレベルを継続的に高めます。

- ポリシーによるガバナンス（Policy as Code）:
  - 大規模組織では、Terraformにおけるリソース作成をガードレールで統制することも重要です。HashiCorp Sentinel（Terraform Enterprise/Cloud向け）やOpen Policy Agent (OPA)を用いて、「特定リージョンでは特定インスタンスタイプのみ許可」「タグXが無いリソースは適用禁止」などのポリシーをコード化し、Terraform実行時にチェックできます​。Terraform Cloudの有償機能であるSentinelを使えば、プラン時に組織ポリシー違反を検出して適用をブロックする運用も可能です​。これにより個々のエンジニアのミスを組織レベルで防ぎ、セキュリティとコンプライアンスを強化できます。

以上のように、IAM・状態・機密情報・継続チェックの観点で多層防御を施すことで、Terraform利用時のセキュリティ態勢を大きく強化できます​。

## CI/CDとの統合（GitHub Actions、CodePipeline 等）

- TerraformによるIaCは、継続的インテグレーション/デリバリー(CI/CD)パイプラインと組み合わせることで一貫性と効率が向上します。手動で直接Terraformを実行するのではなく、コード管理→CI/CD経由で適用するのが理想です​。以下に主要な統合ポイントを示します。

- プランと適用のパイプライン化:
  - GitHubなどのリポジトリにコードをプッシュすると、自動でTerraformのフォーマットチェック、lint、terraform planを実行し、結果を開発者が確認できるようにします。例えばGitHub ActionsのWorkflowを用いて、プルリクエスト時にterraform planを走らせ、その差分をPRコメントに貼り付ける運用が一般的です。承認後、mainブランチへのマージでterraform applyが自動実行されるようにすれば、人為ミスを減らしインフラ変更手続きを標準化できます。AWS CodePipeline/CodeBuildで同様のパイプラインを構築することも可能です。例えばCodePipelineでソース（CodeCommitやGitHub）検出→CodeBuildプロジェクトでTerraform plan実行（承認ステップを挟む）→本番アカウントに適用、という手順を組みます。Terraform実行用のIAMロールはCodeBuildにアタッチし、コード中に認証情報を含めない形にします。

- GitHub ActionsとOIDC連携:
  - GitHub ActionsからAWSを操作する際のベストプラクティスとして、OIDC（OpenID Connect）によるフェデレーション認証があります。以前はAWSユーザのアクセスキーをGitHubシークレットに登録していましたが、長期キーの漏洩リスクが指摘されています​。OIDCを用いると、GitHubから発行される一時トークンを介してAWS側で事前に信頼したIAMロールをAssumeできるため、GitHub上にクラウド資格情報を置かずに済み非常に安全です​。具体的にはAWS側でtoken.actions.githubusercontent.comを信頼するOIDCプロバイダとIAMロールを作成し、そのロールをGitHub Actionsがジョブ実行時にAssumeします。この仕組みにより、CI/CD用のAWS認証はジョブ毎に動的に発行され自動失効する短期クレデンシャルとなり、権限の細かな制御（GitHubリポジトリ・ブランチ条件ごとにAssume可能ロールを限定等）も可能です​。Terraform運用でもこのOIDCパターンを採用することで、GitHubから安全にterraform applyを実行できます。

- マルチアカウント環境でのCI/CD:
  - AWSでは本番用と開発用でアカウントを分離するのが一般的です。それぞれのAWSアカウントに対してTerraformを適用する場合、CI側から対象アカウントのIAMロールをAssumeする構成にします。例えば開発用・本番用それぞれに「Terraform適用用ロール」を作成し、CIジョブ上で環境に応じてAssume RoleしてからTerraformを実行します。これにより1つのCIパイプラインから複数アカウントに安全にデプロイできます。ブランチやワークスペースによってAssumeするロールを変えることで、誤って本番に開発コードを適用するといった事故も防ぎます（ブランチ名とIAMロールARNをマッピングする等）。

- Terraform Cloud / Enterpriseの活用:
  - Terraform Cloud(=TFC)を利用すると、GitHubなどのVCSと連携したTerraformの自動実行基盤をSaaSとして利用できます。リポジトリとTFCワークスペースを連携すれば、コード変更時に自動planが走り、Web上で確認してからapplyを実行（手動または自動）できます。TFC上で状態も安全に管理され、チームで状態を共有しやすくなります​。さらにSentinelポリシー（組織のガバナンスルール）や実行のロールベースアクセス制御、通知連携などエンタープライズ機能も利用できます​。小規模ならTerraform Cloudの無料プランで十分恩恵を得られるでしょう。特にTerraform Cloudはplan毎にコスト見積もりを表示する機能（Infracost連携）も提供しており、変更による予想コスト増減を事前に把握できます。これをCI段階でチェックし、予算を超えるインフラ変更を防ぐといったコントロールも可能です。

- ロールバックと監査:
  - CI/CDでTerraformを適用する場合でも、万一の失敗に備えてロールバック手順を用意します。Terraformの場合はterraform destroyでリソース削除ができますが、本番では現実的でないため、バージョン管理された過去の状態（S3のVersionやTerraform CloudのState History）から手動でリソースを復旧する手順を決めておきます​。また、全てのapply操作は履歴（Terraform Cloudの履歴やCodeBuildのログ）に残し、何がいつ誰によって適用されたか監査できるようにしておきます。前述のように、本番環境への変更はCI/CD経由に限定し、人間が直接実行するのは「ブレークグラス（緊急時対応）ロール」のみ許可するなどの運用ポリシーも有効です​。

以上をまとめると、TerraformをCI/CDに統合することで変更フローを標準化・自動化し、人為ミスや構成ずれを減らせます。特にGitHub Actions＋OIDCやTerraform Cloudなどの最新ツールを活用することで、より安全かつ効率的なIaCデプロイが可能です​。

## コスト最適化の工夫（モジュール化、ワークスペース活用、Terraform Cloud/Backendの活用）

IaCを活用することでインフラコストの最適化にも寄与できます​。Terraform自体はリソースの効率利用を直接制御するものではありませんが、以下の工夫により無駄な支出を抑えられます。

- モジュール化による標準化と再利用:
  - 前述したコードのモジュール化は運用コスト削減だけでなく、インフラの過剰プロビジョニング防止にもつながります。例えば、共通モジュールでタグ付けや容量指定のルールを一元管理すれば、すべての環境で適切なリソースサイズやライフサイクルポリシーを適用できます。その結果、開発環境だけ不要に大きなインスタンスを作るミスや、削除漏れリソースが放置されるリスクを減らせます。一貫した設定により「いつの間にか高額請求」のような事態を防ぎ、必要最小限のリソースで運用できるようになります。

- Terraformワークスペース/マルチ環境の活用:
  - Terraformのワークスペース機能や複数状態ファイルを活用し、1つのコードで複数環境を管理できます。例えば開発・本番でほぼ同じ構成をワークスペースで切り替えてデプロイすれば、コードの重複を書かずに済みます。これはコード管理のコスト削減につながり、結果的に人為ミス低減からのコスト節減効果があります。ただし前述の通りワークスペース利用時は誤適用リスクに注意が必要です​。安全策として、環境ごとに明示的な変数（例えばvar.environment）を使い、これによりリソース名や数量を変えるようにしておくと、誤った環境に適用しようとした際に明確に差分が出て気付きやすくなります。また、開発環境ではcountでリソース数を少なく、本番では多くする、といったパラメータ調整もコードから容易に行えるため、環境に応じたスケーリングでコストを調整できます。

- Terraform BackendとCloudの活用:
  - リモートバックエンドを用いた状態管理やTerraform Cloudの利用は、運用管理コストの削減につながります。例えば自前で状態ファイル管理をせずTerraform Cloudに任せれば、チームでのロック競合やバックアップ管理に労力を割く必要がありません​。またTerraform Cloudは無料枠で複数のワークスペースを扱えるため、開発・ステージング・本番をそれぞれ別ワークスペース+別バックエンドで管理し、UI上で差分比較やコスト見積りを確認する、といった高度な運用も追加コストなしで可能です。状態管理の信頼性向上と運用負荷減は間接的に障害対応などにかかるコストを削減します。

- タグとライフサイクルによるコスト管理:
  - 前述したデフォルトタグを活用し、すべてのリソースに環境や用途のタグを付けておくことで、コスト分析・最適化が容易になります。例えば月次で開発環境のリソースコストを集計し、予算と比較して不要なリソースを削除するといったサイクルを回せます。Terraformで定義していることで削除や変更もスクリプト的に一括実行でき、手動管理に比べリソースの整理がしやすい利点もあります。また、Terraformのライフサイクル機能（prevent_destroyフラグやcreate_before_destroyオプション）を適切に使うことで、不要資源の確実な削除やリソース置換時のダウンタイム最小化ができます。結果として無駄な二重リソース期間を無くし、コスト効率を高められます。

- オンデマンド環境の構築と破棄:
  - Terraformを使えば開発用の一時環境を簡単に構築・破棄できるため、必要な時だけ環境を起動し終われば破棄する、といった運用が現実的になります。例えば夜間や週末は開発環境をTerraformで一時的にdestroyし、利用時にapplyで再構築する、といったインフラのオンデマンド化も可能です。手作業では煩雑な操作もIaCならスクリプト一発で実行できるため、インフラの停止・再開を自動化しやすくなり、その分のコスト削減効果が期待できます。

以上のように、Terraform導入自体が運用効率化による人的コスト削減をもたらしますが、それに加えてインフラリソースのライフサイクルやスケーリングをコードで調整できることが金銭的コストの最適化にもつながります。​

## マルチリージョン・マルチアカウントへの対応

企業利用ではAWSのマルチアカウント（複数AWSアカウント）・マルチリージョン戦略が一般的です。Terraformでこれらに対応するポイントを解説します。

- マルチアカウント構成:
  - 開発用・本番用などAWSアカウントを分離している場合、Terraformコードの構成管理を明確に分けます。典型的にはアカウントごとにバックエンド（状態保管）を分離し、変数やworkspaceで対象アカウントIDを切り替える方法があります。本番アカウント用の状態には強いアクセス制限をかけ（前述のようにCI/CDサービスアカウントと緊急時用ロールのみ書き込み可）、開発者がうっかり本番を操作できないようにします​。Terraformのプロバイダー設定では、AWS_PROFILEや一時クレデンシャルを切り替えることで別アカウントに適用できます。推奨される方法はAssumeRoleを使い、ある「管理アカウント」から各対象アカウントのIAMロールをAssumeして適用する構成です。例えばOrganization管理アカウントから、Terraformで子アカウント用のIAMロール（必要最小権限付き）を順次Assumeしてリソースを作成する、といった実装が可能です。この際、Terraformのプロバイダにaliasを付けて複数定義し、provider = aws.account1のように指定すると一度の計画・適用で複数アカウントにまたがるリソースを扱えます。ただし依存関係が複雑になる場合は、アカウント単位でTerraformプロジェクトを分ける（ディレクトリやワークスペースを分離する）アプローチも検討します。その方が万一一つの環境でエラーが起きても他環境に影響せず、障害範囲が局所化します​。

- マルチリージョン展開:
  - DR（災害対策）やグローバルサービス展開のために、同一構成を複数リージョンにデプロイするケースがあります。Terraformではリージョンを変えたデプロイをパラメータだけ変更して行えるように、変数var.regionを用意してプロバイダ設定に渡す方法があります。あるいはプロバイダをリージョン別にalias指定し、リソース定義をループまたはモジュール呼び出しで二重化することも可能です。例えば、for_eachでリージョンリストを回し、各リージョンに同じモジュールを適用するようなコードを書くこともできます。ただし状態管理上リージョンを跨ぐリソースは依存関係が複雑になるため、リージョンごとに状態を分けることが望ましいです。一つの状態ファイルに複数リージョンのリソースが混在すると、リージョンAの変更がリージョンBにも影響を与える恐れがあります。そこで、リージョン別にTerraformのワークスペースを用意するか、Terraform Cloudのワークスペースを分ける、あるいはバックエンドのキーを分ける（例：myapp/prod/us-east-1/terraform.tfstateと.../ap-northeast-1/...）ことで完全に分離します。

- ネットワークや依存リソースの共有: 
  - マルチアカウント/リージョンでは、ネットワーク（VPCやSubnet）、IAMロール、Transit Gatewayなど共有リソースの扱いが課題になります。Terraformではデータソースを使って他のスタックで作成済みのリソースを参照できます。例えば「共有サービスアカウント」でVPCやIAMロールを管理し、それを他アカウントから参照する場合、TerraformのdataリソースでそのIDやARNを取得して組み込みます。Cross-accountの参照には適切なアクセス許可（リソースポリシーでのAllow）を設定し、Terraform実行ロールに閲覧権限を与える必要があります。また、Terraformの状態を別アカウントから参照できるリモート状態データソースもあります。例えばVPCを管理するTerraformプロジェクトの出力値を、別プロジェクトからterraform_remote_state経由で読み込むことが可能です。これにより厳格にスタックを分離しつつも必要な値を受け渡しできます。ただし依存が増えると運用が複雑化するため、可能な限り依存先は固定値（VPC CIDRや共有リソースのARNを手入力orSSMパラメータ経由など）で渡すのも一案です。

- 組織的な管理:
  - AWS Organizationsを使っている場合、Terraformで組織単位の設定（SCPやOUの作成）もコード化できます。Terraformにはaws_organizations_*リソースがあり、組織アカウントのプロビジョニングや管理ポリシー適用もIaCで行えます。これにより新規アカウント追加時の設定漏れを防ぎ、セキュアなガバナンスを効かせられます。マルチアカウント環境では各アカウントに同じTerraformコードをデプロイするケースが多いため、Terraform moduleの活用が鍵となります。共通部分をモジュール化し、各アカウント固有の差分（リージョンやサイズ）は変数で与えることで、コード重複なく多数の環境を維持できます。

以上により、Terraformは単一環境だけでなく複数環境・リージョンを統一的に管理する力を発揮します。重要なのは、環境ごとの状態の独立性を保つことと、アクセス管理を厳格に分離することです。適切に設計すれば、Terraformで大規模マルチ環境を効率よく制御可能です。

ここからは、具体的なユースケースごとの代表的なAWSアーキテクチャ構成例を紹介します。それぞれTerraformでどのように構築・管理できるか、構成図やモジュール設計の観点も交えて説明します。

## 1. Webアプリケーション構成（例：ALB + EC2 または ECS）

- 典型的なWebシステムは、ロードバランサーとスケーラブルなアプリケーションサーバ群で構成されます。AWSでは**ALB（Application Load Balancer）**をインターネットからのフロントエンドに配置し、バックエンドにEC2のAuto Scaling GroupまたはECSのデプロイメントを配置するパターンが一般的です。 

- 図は、Amazon EC2およびECS(Fargate)を用いた高可用性Webアプリケーション構成の一例です。パブリックサブネットに配置したALBが外部からのHTTP/HTTPSリクエストを受け取り、プライベートサブネット内のEC2インスタンス上で動作するコンテナ（またはECSのFargateタスク）にトラフィックを中継しています。各サブネットは別々のAZに属しており、ALBとバックエンドがマルチAZ冗長化されています。ECS Fargateを採用することで、コンテナ実行基盤のEC2管理を省きつつ自動スケーリングを実現しています。また、アプリケーションのコンテナイメージはECR（Elastic Container Registry）に格納されており、デプロイ時に最新イメージを取得してサービスを更新できるようになっています。

Terraformでこの構成を構築する場合、以下のようなリソースを定義・組み合わせます。

- VPCとネットワーク:
  - aws_vpcやaws_subnetで必要なVPC・サブネット（パブリック2つ、プライベート2つなど）を作成します。合わせてaws_internet_gatewayやaws_route_tableでインターネット接続を設定し、パブリックサブネットからIGW経由で外部アクセス、プライベートサブネットはNAT経由でインターネット通信、といったルーティングもTerraformで定義します。

- セキュリティグループ:
  - aws_security_groupでALB用、EC2/ECS用のSGを作成します。ALB用SGは80番/443番をインターネットから許可し、EC2/ECS用SGはALBのSGからの流入を許可、といったルールを記述します。TerraformではSGルールをリソースブロック内に直接書くこともできますが、ベストプラクティスとしてaws_security_group_ruleリソースを使い分離すると管理しやすいです​。

- ALBの定義:
  - aws_lbでALB本体を作成し、aws_lb_target_groupとaws_lb_listenerでターゲットグループとリスナー（例: ポート80/443の処理とターゲットグループ関連付け）を設定します。ターゲットグループのターゲットは後述のEC2インスタンスまたはECSサービスになります。

- EC2 Auto Scaling構成（オプション）:
  - EC2を使う場合、aws_launch_templateやaws_autoscaling_groupでスケーリンググループを定義します。User Dataでアプリケーション起動スクリプトを記述し、起動時に自動でアプリを立ち上げるようにします。aws_autoscaling_attachmentを用いて先のALBターゲットグループとASGを関連付け、インスタンスが起動するたびにALBに登録されるようにします。またaws_ec2_capacity_reservationやaws_autoscaling_schedule等を使えばピーク時のスケーリングを調整できます。

- ECSクラスターとサービス（オプション）:
  - ECSを使う場合、まずaws_ecs_clusterでクラスターを定義します。Fargate利用時はEC2インスタンス不要ですが、aws_ecs_task_definitionで使用リソース（CPU/メモリ）やコンテナ定義（イメージ、環境変数、ポートマッピングなど）を記述します。次にaws_ecs_serviceでサービスを作成し、desired count（タスク数）や使用するサブネット/セキュリティグループ、そしてALBのターゲットグループとの関連付けを設定します（load_balancerブロックでターゲットグループARNとコンテナ名/ポートを指定）。Terraform AWS ProviderはECSとALBの連携もサポートしており、これらリソース定義によってデプロイと同時にALBにターゲットが登録されます。

- その他周辺サービス:
  - Webアプリでは必要に応じてRDSなどデータベースを作成しEC2/ECSから接続させたり、CloudWatchでログ/メトリクス収集したりします。これらもaws_db_instanceやaws_cloudwatch_log_group等のリソースでコード化可能です。Route53のaws_route53_recordで独自ドメインをALBのDNS名に関連付けたり、ACMのaws_acm_certificateでSSL証明書をプロビジョニングしてALBリスナーに適用することもTerraformで自動化できます。

以上により、Terraformコード上ではVPCモジュール、ALBモジュール、EC2(またはECS)モジュールを組み合わせて記述する形になります。コミュニティの汎用モジュール（例：terraform-aws-modules/alb や terraform-aws-modules/ec2-auto-scaling）を使えば、細かいリソース単位ではなく高レベルなパラメータ指定のみで同様の構成を構築できます。

## 2. データ分析基盤構成（例：S3 + Glue + Athena + QuickSight）

AWS上で構築するデータ分析基盤の代表例として、データレイクを中心としたサーバーレス分析パイプラインが挙げられます。典型的には下記のような構成になります。

- データレイク (Amazon S3):
  - 分析対象データはAmazon S3バケットに蓄積します。生データ（Raw）、加工データ（Processed）、分析用パーティションデータなど、用途別にプレフィックスやバケットを分けて管理します。例えばraw/プレフィックスにCSVやJSONが投入され、GlueなどでParquet変換してanalytics/プレフィックスに保存、という形です。Terraformではaws_s3_bucketリソースでバケットを作成し、バージョニングやライフサイクルルール（一定期間後にIA/Glacierに移行や削除）もコード化できます。また、分析基盤専用のKMSキーをaws_kms_keyで作成しS3バケットを暗号化する設定や、必要に応じてクロスアカウントで参照できるようなバケットポリシーも記述します。

- データカタログ & ETL (AWS Glue):
  - GlueはデータカタログとETL(抽出・変換・ロード)処理を担います。Glueデータカタログではaws_glue_catalog_databaseやaws_glue_crawlerリソースを用いて、S3上のデータからスキーマを自動推論しテーブル定義を作成できます。TerraformでGlueクローラを設定し、対象バケットやプレフィックス、スキーマ検出の設定（CSVヘッダ有無等）をコード化しておけば、新たなデータが来た際に定期実行でテーブルスキーマが更新されます​。また、複雑な変換が必要な場合はGlue ETLジョブ（Spark環境でのPySpark/Scalaスクリプト）をaws_glue_jobリソースでデプロイ可能です。ジョブのスケジュール実行にはaws_glue_triggerを使い、Cron式やイベントで起動できます。TerraformでGlue周りを管理することで、手動でコンソール設定すると煩雑なスキーマ管理やジョブ依存も一元的にコード管理できます。

- クエリエンジン (Amazon Athena):
  - AthenaはS3上のデータに対しSQLクエリを実行できるサービスです。Glueデータカタログで定義されたテーブルに対してクエリを投げられます。Terraformではaws_athena_databaseやaws_athena_workgroupでワークグループ（クエリ実行環境）の設定ができます。ワークグループではクエリ結果の出力先S3バケットや暗号化設定、そしてクエリごとのコスト制限等をポリシーで定義可能です。分析基盤ではしばしばAthenaクエリ結果を別S3に出力し、それを二次利用するパターンがあります。Terraformにより開発用・本番用のAthenaワークグループを分け、利用権限（IAM）を制御するといったガバナンスもコードで実装できます。

- BIダッシュボード (Amazon QuickSight):
  - QuickSightはAWSのBI（Business Intelligence）サービスで、Athena等からデータを取得してダッシュボードを作成できます。QuickSight自体の設定項目はTerraformの直接サポートが限定的ですが、データソースやデータセット定義は一部API経由で管理できます。例えばAthenaへのデータソース接続設定を作成し、特定のAthenaクエリ（ビュー）をQuickSightのデータセットとして定義し、それをダッシュボードで視覚化するといった流れです。Terraformでは対応リソースが限られるため、QuickSightの設定は手動またはAWS CLIで行い、ダッシュボードID等をTerraformの変数に入力して他リソース（SNS通知設定など）と連携するケースもあります。

下図は、AWS上におけるサーバーレス分析基盤のアーキテクチャ例を示しています​。S3に蓄積されたデータに対し、定期的にAWS LambdaやAWS Glueクローラー (Crawler) が起動してスキーマをGlueデータカタログに登録します。AnalystやアプリケーションからAthenaを通じてSQLクエリを実行すると（図中③）、Glueデータカタログのスキーマ情報を参照しつつS3上のデータをスキャンして結果を返します​。QuickSightはAthenaにクエリを投げて可視化を行い（図中④）、ユーザーはブラウザからダッシュボード経由で分析結果を得られます​。この例では生データ収集にAWS Lambdaを使っています（図中①）が、実際にはKinesis FirehoseでリアルタイムにS3に取り込むケースや、Glue ETLジョブでバッチ変換するケースなど様々です。重要なのは、S3+Glue+Athena+QuickSightによりサーバー管理不要でデータ蓄積から可視化まで完結している点です。

Terraformでこれらを管理する際、GlueクローラーやAthenaワークグループなど構成要素が多いため、モジュール化しておくと便利です。例えば「データレイク基盤モジュール」を用意し、その中でS3バケット、Glueデータベース、クローラー設定、Athenaワークグループ設定を一括で作成するようにします。入力変数として「テーブル名リスト」「スケジュール」などを渡せる汎用モジュールにすれば、新しいデータソースが増えた際もモジュール呼び出しを追加するだけで統一的な設定を展開できます。

## 3. コンテナマイクロサービス構成（例：EKS + Fargate）

マイクロサービスアーキテクチャでは、複数の独立デプロイ可能なサービスをコンテナとして実行し、サービス間通信やスケーリングを管理します。AWSでコンテナによるマイクロサービスを実現する方法はいくつかありますが、代表的なのが**Amazon EKS (Elastic Kubernetes Service)**におけるFargateの活用です。EKSはフルマネージドなKubernetesサービスで、Fargateを組み合わせることでワーカーノードを持たないサーバレスなKubernetesクラスタを構築できます​。

- EKS + Fargate構成の特徴:

  - KubernetesコントロールプレーンはAWSにより管理され、高可用に冗長化されています。利用者はコントロールプレーンを意識せずクラスターAPIを使用できます。
  - Fargateプロファイルを設定することで、特定の名前空間やPodに属するワークロードを自動的にFargate（AWS側で起動するコンテナ実行環境）上で実行できます。これによりEC2ノードを自前で管理・スケーリングする必要がなくなります​。
  - 各Pod（コンテナ）は他とカーネルやインスタンスを共有しない単一の隔離環境で実行されるため、セキュリティとマルチテナンシーが強化されます​。
  - DaemonSetなど一部制約（Fargateではホストレベル常駐コンテナ不可など）はありますが、負荷に応じたスケーリングやサービスディスカバリは通常のKubernetesと同様に利用できます。

構成図としては、EKSクラスタに複数のマイクロサービス（それぞれDeploymentやPodとしてデプロイ）が存在し、サービスディスカバリやIngressコントローラを介して通信するイメージです。ALB Ingress Controller（AWS Load Balancer Controller）を導入すれば、KubernetesのIngressリソース定義に基づいてALBが自動プロビジョンされ、各サービスへのルーティングが構成されます。サービス間通信にはClusterIPやService Mesh（AWS App Meshなど）を用いることもあります。 

TerraformでEKS＋Fargateのマイクロサービス基盤を構築・管理する際のポイント:

- EKSクラスタの作成:
  - aws_eks_clusterリソースでクラスタを作成します。マネージドノードを使わない場合でもVPCのSubnetsやIAMロール（EKS用マスター権限ロール）は指定が必要です。Terraform公式モジュール（terraform-aws-modules/eks）を使うと、クラスタ作成から関連リソース設定まで一括できます。EKSクラスター作成後、aws_eks_fargate_profileリソースでFargateプロファイルを定義します。ここで「特定のNamespaceかつ特定のラベルを持つPodはFargateで実行」という条件を記述します。例えばnamespace = "default"を指定すればデフォルトネームスペースのPodはすべてFargate実行になります。複数プロファイルも定義できるため、基盤系Podはノードグループ、ビジネスロジックPodはFargateなど使い分けも可能です。

- IAMとOIDCプロバイダ設定:
  - EKSではKubernetesのServiceAccountにIAMロールを関連付け（IRSA機能）できます。Terraformではaws_iam_openid_connect_providerでEKSクラスターのOIDCプロバイダーを登録し、aws_iam_roleを各サービス用に作成した上で適切なTrust Policyを設定します。これにより、各マイクロサービスPodからAWSリソース（S3やSQS等）にアクセスする際、他サービスと権限を分離できます。例えば「サービスAはS3バケットXのみ読み書き可」「サービスBはDynamoDBテーブルYのみ可」等をIAMロールで細かく制御し、それをそれぞれのK8s ServiceAccountに紐付けます。TerraformでこれらIAMリソースを定義し、Kubernetes側ServiceAccountリソースもkubectl適用することで、コードでインフラ権限まで管理できます。

- Kubernetesリソースのデプロイ:
  - TerraformはKubernetes providerを用いて、K8sネイティブのDeploymentやService、Ingress等をデプロイすることも可能です。しかしTerraformでアプリケーションManifestを管理するのは賛否あり、HelmやArgo CDとの分担も検討されます。Terraform利用の場合、kubernetes_deploymentやkubernetes_serviceリソースでマニフェスト相当を記述し、イメージ名やレプリカ数を可変にできます。小規模ならTerraformでまとめても良いですが、マイクロサービスが多数になるとTerraformの管理には不向きな部分も出てきます（差分検出が細かく煩雑になる等）。そこで、インフラ（EKSクラスタやFargateプロファイル、IAM）まではTerraformで構築し、その上で動くアプリケーションコンテナは別途HelmチャートやKubernetesマニフェスト管理に委ねるケースもあります。TerraformはあくまでEKS基盤の部分にフォーカスし、CI/CDでkubectl applyを行う戦略です。

- オートスケーリングとモニタリング:
  - マイクロサービスでは各サービスを独立にスケールさせる必要があります。EKSではHorizontal Pod Autoscaler (HPA)を設定することでCPUやカスタムメトリクスに基づきPod数を自動調整できます。こちらもTerraformのKubernetes providerでkubernetes_horizontal_pod_autoscalerリソースを使い定義可能です。さらに、PrometheusやCloudWatch Container Insightsといったモニタリングを導入し、サービスごとにリソース使用量を可視化・アラート設定することが重要です。TerraformではHelm providerを通じてPrometheusやGrafanaのチャートをインストールすることもできますし、CloudWatchエージェント用のConfigMapをデプロイすることもできます。

EKS＋Fargateにより、サーバ管理なしでコンテナマイクロサービスを稼働できます。Fargateは必要なリソースをAWSがオンデマンドにプロビジョニングし管理してくれるため、利用者はアプリケーションのデプロイとスケーリングポリシーに集中できます​。Terraformによってこれら設定をInfrastructure as Code化すれば、マイクロサービス群の構成（サービス数百に及ぶこともあります）も一貫して管理可能で、新しいサービス追加時も既存コードをコピーして変更するだけという効率的な運用が可能となります。

## 4. サーバーレスアーキテクチャ構成（例：API Gateway + Lambda + DynamoDB）

サーバーレスアーキテクチャは、サーバ管理を意識せずにアプリケーションを構築できるスタイルで、AWSではAPI Gateway・AWS Lambda・DynamoDBの組み合わせがその代表例です。典型的なREST APIバックエンドをこのスタックで実装する場合の構成を説明します。 

上図は、API Gatewayをフロントエンドに据え、Lambda関数でビジネスロジックを実行し、結果をDynamoDBに読み書きするアーキテクチャの概略です​。クライアント（Webやモバイルアプリ）はHTTP(S)でAPI Gatewayのエンドポイントにリクエストを送り、対応するLambda関数がトリガーされます。LambdaはDynamoDBテーブルを参照・更新し、処理結果をAPI Gateway経由でクライアントにレスポンスとして返します​。この一連の流れはすべてマネージドサービス上で行われ、開発者はコード（Lambda関数）とテーブル定義に集中すればよく、サーバインフラはAWSにより自動的にスケーリング・管理されます。

この構成をTerraformで構築・管理するポイント:

- API Gateway (REST API):
  - Terraformではaws_api_gateway_rest_apiでREST API自体を定義し、aws_api_gateway_resourceでパス毎のリソース（エンドポイント）、aws_api_gateway_methodでHTTPメソッド毎の設定、aws_api_gateway_integrationでそのメソッドが呼ぶバックエンド（Lambda）の関連付けを記述します。続いてaws_api_gateway_deploymentとaws_api_gateway_stageでAPIをデプロイしステージ（本番v1などURIプレフィックス）を公開します。これらをコード化することで、複数のAPIエンドポイントやバージョン管理を一貫して扱えます。Terraform定義がやや冗長になる部分ではありますが、Lambdaとの結合も含め間違いのない設定を自動適用できます。

- AWS Lambda関数:
  - aws_lambda_functionリソースで関数をデプロイします。Lambdaのコードは通常ZIPファイルにパッケージ化してS3経由で渡します（TerraformでソースからZIPを作る場合は外部プロバイダやnull_resourceでビルドする）。ハンドラ名、ランタイム（例えばNode.js, Python等）、環境変数、メモリ/タイムアウトなどもTerraformで設定可能です。また、上記API Gatewayから呼ばれるための権限を付与するaws_lambda_permissionも必要です。これはAPI Gatewayの特定メソッドからinvokeを許可するリソースで、Terraformで生成できます​。実行ロール（aws_iam_role）も定義し、必要なDynamoDBアクセス権をポリシーで付与します。

- DynamoDBテーブル:
  - aws_dynamodb_tableリソースでNoSQLデータベーステーブルを作成します。パーティションキー・ソートキー、スループットキャパシティ（オンデマンドかプロビジョニングか）、ストリーム有効化などオプションを設定します。Terraformでテーブル定義を行うと、テーブル削除ポリシー（削除時にバックアップを自動作成するかなど）も指定でき、本番データを扱う際の安全策となります。必要ならGlobal Secondary Index (GSI) もサブリソース的に記述できます。作成したテーブル名やARNは後続のLambda実行ロールのポリシーで参照し、特定テーブルへのCRUD権限を許可します。

- 統合とデプロイ:
  - API Gateway側のintegration設定でLambdaのARNを指定し、Lambda側の実行権限でAPI Gatewayを信頼プリンシパルとして許可することで、REST API→Lambdaの接続が完成します。Terraformではリソース間の参照関係を適切に書くことで、依存順序も自動解決されます（API Gatewayの統合がLambda関数の作成後に実行されるよう、自動的にdepends_onが内部考慮される等）。Terraformコードをapplyすれば、APIエンドポイントからテーブルまで一気に構築され、デプロイ直後から動作するはずです。

- カスタムドメインや認証（必要に応じて）:
  - API Gatewayにカスタムドメイン（独自ドメイン）を設定する場合、aws_api_gateway_domain_nameとaws_api_gateway_base_path_mappingを使い、Route53のCNAMEレコードもTerraformで定義します。また、ユーザー認証をCognito等で行う場合、API GatewayのAuthorizerをaws_api_gateway_authorizerで設定し、各メソッドに認証を有効化（aws_api_gateway_method_settings等で指定）します。これらもTerraformで管理可能ですが、シンプルな公開APIであれば不要です。

このように完全サーバレスな構成では、デプロイすべき実体はサービス設定と関数コードのみとなります。Terraformはその設定部分（API・リソース・権限・データストア）を正確に構築する役割を担い、Lambda関数のビジネスロジックコードは別途リポジトリで管理しつつ、CI/CDでビルド・Terraform適用まで行う流れになります。特に環境ごとにステージを分けたり、機能フラグ的にLambda環境変数を切り替えるなどコードとインフラ設定を一元管理できる点がTerraform採用のメリットです。

以上、4つのユースケースについてTerraformを用いたAWSアーキテクチャ構成の例を説明しました。TerraformによるIaCは、正しくベストプラクティスを適用すれば大規模環境でも信頼性・セキュリティ・効率を高められます​。各ユースケース毎にTerraformモジュールを設計し、CI/CDパイプラインに組み込んで運用することで、インフラ管理の生産性と品質向上が期待できます。ぜひ自身のプロジェクトでもこれら手法を検討してみてください。 

## 引用:

ベストプラクティスに関するAWS Prescriptive Guidanceドキュメント​、ならびに各種AWSブログ記事・Terraform公式リソースの内容を参照しました。​
